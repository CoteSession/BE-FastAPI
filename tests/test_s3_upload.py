import asyncio
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from pth_model.infra.s3.s3_manager import S3Manager

async def test_s3_connection():
    """S3 ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ” S3 ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    try:
        s3_manager = S3Manager()
        is_connected = s3_manager.test_connection()
        
        if is_connected:
            print("âœ… S3 ì—°ê²° ì„±ê³µ!")
            print(f"   ë²„í‚·: {s3_manager.bucket_name}")
            print(f"   ë¦¬ì „: {s3_manager.region_name}")
        else:
            print("âŒ S3 ì—°ê²° ì‹¤íŒ¨!")
            
    except Exception as e:
        print(f"âŒ S3 ì—°ê²° ì˜¤ë¥˜: {str(e)}")

async def test_file_upload():
    """íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    try:
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ íŒŒì¼ ìƒì„±
        test_files = []
        test_dir = Path("tests/test_files")
        test_dir.mkdir(exist_ok=True, parents=True)
        
        # ë”ë¯¸ .pth íŒŒì¼ë“¤ ìƒì„±
        for i in range(3):
            file_path = test_dir / f"test_model_{i+1}.pth"
            with open(file_path, 'wb') as f:
                f.write(b"dummy pytorch model data" * 100)  # ë”ë¯¸ ë°ì´í„°
            test_files.append(file_path)
        
        print(f"   ìƒì„±ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼: {[f.name for f in test_files]}")
        
        # S3 ë§¤ë‹ˆì €ë¡œ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
        s3_manager = S3Manager()
        
        # UploadFile ê°ì²´ ì‹œë®¬ë ˆì´ì…˜
        from fastapi import UploadFile
        from io import BytesIO
        
        upload_files = []
        for file_path in test_files:
            with open(file_path, 'rb') as f:
                content = f.read()
                upload_file = UploadFile(
                    filename=file_path.name,
                    file=BytesIO(content)
                )
                upload_files.append(upload_file)
        
        # ì—…ë¡œë“œ ì‹¤í–‰
        results = await s3_manager.upload_files(upload_files)
        
        # ê²°ê³¼ ì¶œë ¥
        success_count = sum(1 for r in results if r['success'])
        print(f"   ì—…ë¡œë“œ ê²°ê³¼: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {len(results) - success_count}ê°œ")
        
        for result in results:
            if result['success']:
                print(f"   âœ… {result['filename']} -> {result['s3_key']}")
            else:
                print(f"   âŒ {result['filename']}: {result['error']}")
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
        for file_path in test_files:
            file_path.unlink()
        test_dir.rmdir()
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ S3 ì—…ë¡œë“œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # 1. S3 ì—°ê²° í…ŒìŠ¤íŠ¸
    await test_s3_connection()
    
    # 2. íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
    await test_file_upload()
    
    print("\nâœ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(main())
